{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ClassId              SignName\n",
      "0        0  Speed limit (20km/h)\n",
      "1        1  Speed limit (30km/h)\n",
      "2        2  Speed limit (50km/h)\n",
      "3        3  Speed limit (60km/h)\n",
      "4        4  Speed limit (70km/h)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv('../data/label_names_eng.csv')\n",
    "print(labels.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../models/model-new.h5')\n",
    "with open('../data/mean_image_rgb.pickle', 'rb') as f:\n",
    "    mean = pickle.load(f, encoding='latin1')\n",
    "print(mean['mean_image_rgb'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "path_to_weights: str = '../data/znaki_rtx_final.weights'\n",
    "path_to_cfg: str = '../data/yolov3_ts_test.cfg'\n",
    "network = cv2.dnn.readNetFromDarknet(path_to_cfg, path_to_weights)\n",
    "network.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "network.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA_FP16)\n",
    "# network.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "# network.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL_FP16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv_0', 'bn_0', 'leaky_1', 'conv_1', 'bn_1', 'leaky_2', 'conv_2', 'bn_2', 'leaky_3', 'conv_3', 'bn_3', 'leaky_4', 'shortcut_4', 'conv_5', 'bn_5', 'leaky_6', 'conv_6', 'bn_6', 'leaky_7', 'conv_7', 'bn_7', 'leaky_8', 'shortcut_8', 'conv_9', 'bn_9', 'leaky_10', 'conv_10', 'bn_10', 'leaky_11', 'shortcut_11', 'conv_12', 'bn_12', 'leaky_13', 'conv_13', 'bn_13', 'leaky_14', 'conv_14', 'bn_14', 'leaky_15', 'shortcut_15', 'conv_16', 'bn_16', 'leaky_17', 'conv_17', 'bn_17', 'leaky_18', 'shortcut_18', 'conv_19', 'bn_19', 'leaky_20', 'conv_20', 'bn_20', 'leaky_21', 'shortcut_21', 'conv_22', 'bn_22', 'leaky_23', 'conv_23', 'bn_23', 'leaky_24', 'shortcut_24', 'conv_25', 'bn_25', 'leaky_26', 'conv_26', 'bn_26', 'leaky_27', 'shortcut_27', 'conv_28', 'bn_28', 'leaky_29', 'conv_29', 'bn_29', 'leaky_30', 'shortcut_30', 'conv_31', 'bn_31', 'leaky_32', 'conv_32', 'bn_32', 'leaky_33', 'shortcut_33', 'conv_34', 'bn_34', 'leaky_35', 'conv_35', 'bn_35', 'leaky_36', 'shortcut_36', 'conv_37', 'bn_37', 'leaky_38', 'conv_38', 'bn_38', 'leaky_39', 'conv_39', 'bn_39', 'leaky_40', 'shortcut_40', 'conv_41', 'bn_41', 'leaky_42', 'conv_42', 'bn_42', 'leaky_43', 'shortcut_43', 'conv_44', 'bn_44', 'leaky_45', 'conv_45', 'bn_45', 'leaky_46', 'shortcut_46', 'conv_47', 'bn_47', 'leaky_48', 'conv_48', 'bn_48', 'leaky_49', 'shortcut_49', 'conv_50', 'bn_50', 'leaky_51', 'conv_51', 'bn_51', 'leaky_52', 'shortcut_52', 'conv_53', 'bn_53', 'leaky_54', 'conv_54', 'bn_54', 'leaky_55', 'shortcut_55', 'conv_56', 'bn_56', 'leaky_57', 'conv_57', 'bn_57', 'leaky_58', 'shortcut_58', 'conv_59', 'bn_59', 'leaky_60', 'conv_60', 'bn_60', 'leaky_61', 'shortcut_61', 'conv_62', 'bn_62', 'leaky_63', 'conv_63', 'bn_63', 'leaky_64', 'conv_64', 'bn_64', 'leaky_65', 'shortcut_65', 'conv_66', 'bn_66', 'leaky_67', 'conv_67', 'bn_67', 'leaky_68', 'shortcut_68', 'conv_69', 'bn_69', 'leaky_70', 'conv_70', 'bn_70', 'leaky_71', 'shortcut_71', 'conv_72', 'bn_72', 'leaky_73', 'conv_73', 'bn_73', 'leaky_74', 'shortcut_74', 'conv_75', 'bn_75', 'leaky_76', 'conv_76', 'bn_76', 'leaky_77', 'conv_77', 'bn_77', 'leaky_78', 'conv_78', 'bn_78', 'leaky_79', 'conv_79', 'bn_79', 'leaky_80', 'conv_80', 'bn_80', 'leaky_81', 'conv_81', 'permute_82', 'yolo_82', 'identity_83', 'conv_84', 'bn_84', 'leaky_85', 'upsample_85', 'concat_86', 'conv_87', 'bn_87', 'leaky_88', 'conv_88', 'bn_88', 'leaky_89', 'conv_89', 'bn_89', 'leaky_90', 'conv_90', 'bn_90', 'leaky_91', 'conv_91', 'bn_91', 'leaky_92', 'conv_92', 'bn_92', 'leaky_93', 'conv_93', 'permute_94', 'yolo_94', 'identity_95', 'conv_96', 'bn_96', 'leaky_97', 'upsample_97', 'concat_98', 'conv_99', 'bn_99', 'leaky_100', 'conv_100', 'bn_100', 'leaky_101', 'conv_101', 'bn_101', 'leaky_102', 'conv_102', 'bn_102', 'leaky_103', 'conv_103', 'bn_103', 'leaky_104', 'conv_104', 'bn_104', 'leaky_105', 'conv_105', 'permute_106', 'yolo_106']\n",
      "['yolo_82', 'yolo_94', 'yolo_106']\n"
     ]
    }
   ],
   "source": [
    "layers_all = network.getLayerNames()\n",
    "print(layers_all)\n",
    "layers_names_output = [layers_all[i[0] - 1] for i in network.getUnconnectedOutLayers()]\n",
    "print(layers_names_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 3)\n",
      "[ 35 120 207]\n"
     ]
    }
   ],
   "source": [
    "probability_minimum = 0.2\n",
    "threshold = 0.2\n",
    "colors = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n",
    "\n",
    "print(colors.shape)\n",
    "print(colors[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_BGR = cv2.imread('../data/yolo_formated/autosave21_01_2013_12_35_10_2.jpg')\n",
    "print(f'Input shape: {image_BGR.shape}')\n",
    "h, w = image_BGR.shape[:2]\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image_BGR, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "network.setInput(blob)\n",
    "start = time.time()\n",
    "output_from_network = network.forward(layers_names_output)\n",
    "end = time.time()\n",
    "\n",
    "print(f'Total time: {end - start:.5f}')\n",
    "\n",
    "bounding_boxes = []\n",
    "confidences = []\n",
    "class_numbers = []\n",
    "for result in output_from_network:\n",
    "    for detected_objects in result:\n",
    "        scores = detected_objects[5:]\n",
    "        class_current = np.argmax(scores)\n",
    "        confidence_current = scores[class_current]\n",
    "\n",
    "        if confidence_current > probability_minimum:\n",
    "            box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
    "\n",
    "            x_center, y_center, box_width, box_height = box_current\n",
    "            x_min = int(x_center - (box_width / 2))\n",
    "            y_min = int(y_center - (box_height / 2))\n",
    "\n",
    "            bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
    "            confidences.append(float(confidence_current))\n",
    "            class_numbers.append(class_current)\n",
    "\n",
    "results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n",
    "\n",
    "if len(results) > 0:\n",
    "    for i in results.flatten():\n",
    "        x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "        box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "\n",
    "\n",
    "        c_ts = image_BGR[y_min:y_min+int(box_height), x_min:x_min+int(box_width), :]\n",
    "\n",
    "        if c_ts.shape[:1] == (0,) or c_ts.shape[1:2] == (0,):\n",
    "            pass\n",
    "        else:\n",
    "            blob_ts = cv2.dnn.blobFromImage(c_ts, 1 / 255.0, size=(32, 32), swapRB=True, crop=False)\n",
    "            blob_ts[0] = blob_ts[0, :, :, :] - mean['mean_image_rgb']\n",
    "            blob_ts = blob_ts.transpose(0, 2, 3, 1)\n",
    "\n",
    "            scores = model.predict(blob_ts)\n",
    "\n",
    "            prediction = np.argmax(scores)\n",
    "            print(labels['SignName'][prediction])\n",
    "\n",
    "            colour_box_current = colors[class_numbers[i]].tolist()\n",
    "\n",
    "            cv2.rectangle(image_BGR, (x_min, y_min), (x_min + box_width, y_min + box_height),\n",
    "                          colour_box_current, 2)\n",
    "            text_box_current = '{}: {:.4f}'.format(labels['SignName'][prediction], confidences[i])\n",
    "            cv2.putText(image_BGR, text_box_current, (x_min, y_min - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, colour_box_current, 2)\n",
    "\n",
    "cv2.imwrite('../result.png', image_BGR)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (35.0, 35.0) # Setting default size of plots\n",
    "image_BGR = cv2.imread('../result.png')\n",
    "print('Image shape:', image_BGR.shape)\n",
    "\n",
    "h, w = image_BGR.shape[:2]\n",
    "print(f'Высота={h} ширина={w}')\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_BGR, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "writer = None\n",
    "h, w = None, None\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame number 1 took 0.81400 seconds\n",
      "Frame number 2 took 0.43000 seconds\n",
      "Frame number 3 took 0.40799 seconds\n",
      "Frame number 4 took 0.38199 seconds\n",
      "Frame number 5 took 0.51000 seconds\n",
      "Frame number 6 took 0.53801 seconds\n",
      "Frame number 7 took 0.42500 seconds\n",
      "Frame number 8 took 0.48300 seconds\n",
      "Frame number 9 took 0.44500 seconds\n",
      "Frame number 10 took 0.39900 seconds\n",
      "Frame number 11 took 0.38900 seconds\n",
      "Frame number 12 took 0.38200 seconds\n",
      "Frame number 13 took 0.38200 seconds\n",
      "Frame number 14 took 0.38199 seconds\n",
      "Frame number 15 took 0.41300 seconds\n",
      "Frame number 16 took 0.38100 seconds\n",
      "Frame number 17 took 0.38600 seconds\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (3, 3)\n",
    "f = 0\n",
    "t = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if w is None or h is None:\n",
    "        h, w = frame.shape[:2]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "    network.setInput(blob)\n",
    "    start = time.time()\n",
    "    output_from_network = network.forward(layers_names_output)\n",
    "    end = time.time()\n",
    "\n",
    "    f += 1\n",
    "    t += end - start\n",
    "    print('Frame number {0} took {1:.5f} seconds'.format(f, end - start))\n",
    "\n",
    "    bounding_boxes = []\n",
    "    confidences = []\n",
    "    class_numbers = []\n",
    "\n",
    "    for result in output_from_network:\n",
    "        for detected_objects in result:\n",
    "            scores = detected_objects[5:]\n",
    "            class_current = np.argmax(scores)\n",
    "            confidence_current = scores[class_current]\n",
    "            if confidence_current > probability_minimum:\n",
    "                box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
    "\n",
    "                x_center, y_center, box_width, box_height = box_current\n",
    "                x_min = int(x_center - (box_width / 2))\n",
    "                y_min = int(y_center - (box_height / 2))\n",
    "\n",
    "                bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
    "                confidences.append(float(confidence_current))\n",
    "                class_numbers.append(class_current)\n",
    "\n",
    "    results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n",
    "\n",
    "    if len(results) > 0:\n",
    "        for i in results.flatten():\n",
    "            x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "            box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "\n",
    "            c_ts = frame[y_min:y_min+int(box_height), x_min:x_min+int(box_width), :]\n",
    "\n",
    "            if c_ts.shape[:1] == (0,) or c_ts.shape[1:2] == (0,):\n",
    "                pass\n",
    "            else:\n",
    "                blob_ts = cv2.dnn.blobFromImage(c_ts, 1 / 255.0, size=(32, 32), swapRB=True, crop=False)\n",
    "                blob_ts[0] = blob_ts[0, :, :, :] - mean['mean_image_rgb']\n",
    "                blob_ts = blob_ts.transpose(0, 2, 3, 1)\n",
    "\n",
    "                scores = model.predict(blob_ts)\n",
    "                prediction = np.argmax(scores)\n",
    "\n",
    "                colour_box_current = colors[class_numbers[i]].tolist()\n",
    "\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_min + box_width, y_min + box_height),\n",
    "                              colour_box_current, 2)\n",
    "\n",
    "                text_box_current = '{}: {:.4f}'.format(labels['SignName'][prediction], confidences[i])\n",
    "                cv2.putText(frame, text_box_current, (x_min, y_min - 5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, colour_box_current, 2)\n",
    "\n",
    "    cv2.namedWindow('Camera view', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('Camera view', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего обработано кадров 257\n",
      "Заняло 106.47058 секунд\n",
      "FPS: 2.4\n"
     ]
    }
   ],
   "source": [
    "print('Всего обработано кадров', f)\n",
    "print(f'Заняло {t:.5f} секунд')\n",
    "print('FPS:', round((f / t), 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}